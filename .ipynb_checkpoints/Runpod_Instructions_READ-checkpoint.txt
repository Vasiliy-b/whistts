
Please register for RunPod at: https://get.runpod.io/955rkuppqv4h

Example tutorial for learn how to install and use RunPod is below

(starts at 22:03) : https://youtu.be/KW-MHmoNcqo?si=QN8X8Sjn13ZYu-EU&t=1323

RunPod permanent network storage tutorial : https://youtu.be/8Qf4x3-DFf4

When deploying a Pod select min 24 GB GPU like RTX 3090 but 4090 should work way faster or 5090 even better

Recommended GPUs are 48 GB for maximum speed A40, A6000, L40S or RTX 6000 PRO

select runpod template - this is important

RunPod Pytorch 2.2.0
runpod/pytorch:2.2.0-py3.10-cuda12.1.1


Edit the pod configuration:
Set the volume disk size to 50 GB or your preferred size according to number of models you want to download or such.

Add HTTP port 7861 to the exposed ports list to enable proxy connection.
By default, it will start with the --share option for Gradio sharing.

Upload all files to the workspace folder.

To install, run the following commands:


export HF_HOME="/workspace"
chmod +x Runpod_Install.sh
./Runpod_Install.sh


To use after installation:

Open a new terminal and run the following code each time you start:

This will prompt you to choose which model to load. Run in a new terminal:


cd /workspace
export HF_HOME="/workspace"
export PYTHONWARNINGS="ignore"
export HF_HUB_ENABLE_HF_TRANSFER=1
unset LD_LIBRARY_PATH
cd /workspace/Whisper-WebUI
source venv/bin/activate
python app.py --share


You will receive a Gradio live link, and you'll be able to connect via the proxy on port 7861.

Pay attention to the Gradio share link among the printed messages.

Remove the --share option if you don't want the Gradio live link

If you rent multiple GPU machine, you can start different instances on each GPU by changing export CUDA_VISIBLE_DEVICES=1 2 3 4 etc

If you restart the pod you have to run below command 1 time after each restart

apt update --yes
apt install ffmpeg --yes
